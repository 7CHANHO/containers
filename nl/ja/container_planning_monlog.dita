<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE concept PUBLIC "-//IBM//DTD DITA IBM Concept//EN" "ibm-concept.dtd">
<concept id="container_planning_monlog" xml:lang="ja-jp">
<title>モニタリングとロギング</title>
<titlealts>
<navtitle>モニタリングとロギング</navtitle>
<searchtitle><keyword conref="cloudoeconrefs.dita#cloudoeconrefs/containerlong"></keyword> でのログとメトリックの表示</searchtitle></titlealts>
<shortdesc conref="monitoringandlogging/container_ml_ov.dita#container_ml_ov/shortdesc"></shortdesc>
<conbody>
<note type="important">このサービスは、機密データの処理を目的としたものではありません。</note>
<p conref="monitoringandlogging/container_ml_ov.dita#container_ml_ov/intro"></p>
<fig id="fig_architecture">
<title>モニタリングおよびロギング・サービスのアーキテクチャー</title><image href="images/architecture_logmet.svg" placement="break">
<alt>モニタリングおよびロギング・サービスのアーキテクチャー</alt></image></fig>
<dl>
<dlentry>
<dt>モニタリング</dt>
<dd><ph id="monitoring">コンテナーのメトリックはコンテナー外部から収集されるので、コンテナー内部にエージェントをインストールして保守する必要はありません。コンテナー内エージェントでは、コンテナーが急速に作成されて破棄されるような、短期間だけ存在する軽量クラウド・インスタンスおよび自動スケーリング・グループに対して、
オーバーヘッドおよびセットアップ時間がかなり大きくなる可能性があります。外部からのこのデータ収集方法によって、こういった問題点がなくなり、モニタリングの負担がユーザーにかからなくなります。</ph></dd>
<dd id="default_metrics"><p>ホスト内で実行中のプロセスが、メトリックに関するエージェントレス・モニタリングを実行します。このプロセスは<term>クローラー</term>とも呼ばれ、すべてのコンテナーから以下の情報を常に収集します。</p>
<p><ul>
<li>CPU</li>
<li>メモリー </li>
<li>ネットワーク情報</li></ul></p>
<p>このメトリック・データは Graphite で収集され、<keyword conref="cloudoeconrefs.dita#cloudoeconrefs/bluemix_short"></keyword> ユーザー・インターフェースと拡張モニタリング・ビューの両方で表示されます。Docker 規則およびグループ・アカウンティング情報が、モニタリング・データ収集の基本的メカニズムとして使用されます。</p>
<p>データを収集するためにインストールされているプラグインのリストは、<filepath>/etc/collectd/collectd.conf</filepath> で参照できます。それらのプラグインの機能について詳しくは、<xref href="https://collectd.org/documentation/manpages/collectd.conf.5.shtml" format="html" scope="external">collectd の資料</xref>を参照してください。</p></dd></dlentry></dl>
<dl>
<dlentry>
<dt>ロギング</dt>
<dd><ph id="logging">コンテナーのログは、メトリックと同様に、クローラーを使用してコンテナー外部からモニターおよび転送されます。そのデータは、クローラーによって <tm trademark="Bluemix" tmtype="tm">Bluemix</tm> のマルチテナント <xref href="https://www.elastic.co/products/elasticsearch" format="html" scope="external">Elasticsearch</xref> に送信されます。
この処理方法は他のコンテナー内エージェントによって収集されるログと似ていますが、わざわざコンテナー内部にエージェントをインストールする必要はありません。</ph>
</dd>
<dd><p>デフォルトでは、クローラーは以下の場所から情報を取得します。</p><ul id="default_logs">
<li><filepath>/var/log/messages</filepath>: システム・メッセージ。</li>
<li><filepath>/docker.log</filepath>: Docker ログ。<p>Docker ログ・ファイルはコンテナー内にファイルとして保管されることはありませんが、収集されます。
このログ・ファイルがデフォルトで収集されるのは、コンテナーの <codeph>stdout</codeph> (標準出力) 情報と <codeph>stderr</codeph> (標準エラー) 情報の公開に関する標準 Docker 規約であるためです。コンテナー・プロセスが <codeph>stdout</codeph> または <codeph>stderr</codeph> を出力すると、その情報が収集されます。</p></li></ul>追加のログを収集するには、<xref href="container_single_ui.dita#gui/env_keys_group" format="dita" scope="local">GUI</xref> または <xref href="container_single_cli.dita#container_single_cli">CLI</xref> でコンテナーを作成する際に、<codeph>LOG_LOCATIONS</codeph> 環境変数をログ・ファイルへのパスと共に追加します。</dd></dlentry></dl>
<p>ログとメトリックの収集方法、そしてカスタム・ダッシュボードの作成方法について詳しくは、<xref href="../services/cloud-monitoring/containers/analyzing_metrics_bmx_ui.html#analyzing_metrics_bmx_ui" format="html" scope="peer">コンテナーのモニタリングとロギング</xref>を参照してください
</p></conbody></concept>
